[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Utilisation de modèles de régression à coefficients variant dans le temps pour la prévision conjoncturelle",
    "section": "",
    "text": "Ce site web contient l’ensemble des documents utilisés pendant l’atelier D2E du 16 mars 2023 sur l’utilisation de modèles de régression à coefficients variant dans le temps pour la prévision conjoncturelle.\nVous y trouverez les slides ainsi que le TP.\nPour le TP, vous pouvez soit utiliser le datalab en cliquant ici  soit installer localement les packages en suivant le manuel d’installation."
  },
  {
    "objectID": "manuel_installation.html",
    "href": "manuel_installation.html",
    "title": "Installation de tvCoef",
    "section": "",
    "text": "Pour utiliser tvCoef, il faut il faut avoir la version 17 de Java (ou une version supérieure).\nPour savoir quelle version de Java est utilisée par R, utiliser le code suivant :\n\nlibrary(rJava)\n.jinit()\n.jcall(\"java/lang/System\", \"S\", \"getProperty\", \"java.runtime.version\")\n\n[1] \"18+36-2087\"\n\n\nSi le résultat n’est pas sous la forme \"17xxxx\" c’est que vous n’avez pas Java 17 !\nSi l’on a pas cette version d’installée et que l’on n’a pas les droits d’administrateur pour installer Java il faut alors installer une version portable de Java. Pour installer une version portable de java, télécharger par exemple le fichier Windows 10 x64 Java Development Kit disponible sur https://jdk.java.net/java-se-ri/17, le dézipper et le mettre par exemple sous \"D:/Programmes/jdk-17\".\nPour configurer R avec une version portable de Java, trois solutions :\n\nAvant avant tout chargement de package nécessitant Java (rJava…) (si vous avez lancé le code précédent, relancez donc R) :\n\n\nSys.setenv(JAVA_HOME='D:/Programmes/jdk-17')\n\n\nPour éviter de faire cette manipulation à chaque fois que l’on relance R, deux solutions :\n\nmodifier le JAVA_HOME dans les variables d’environnement de Windows (voir https://confluence.atlassian.com/doc/setting-the-java_home-variable-in-windows-8895.html).\nmodifier le .Renviron : depuis R lancer le code file.edit(\"~/.Renviron\"), ajouter dans le fichier le chemin vers la version portable de Java comme précédemment (JAVA_HOME='D:/Programmes/jdk-17'), sauvegarder et relancer R.\n\n\nIl reste maintenant à installer les packages :\n\nremotes::install_github(\"palatej/rjd3toolkit\")\nremotes::install_github(\"palatej/rjd3sts\")\nremotes::install_github(\"AQLT/tvCoef\")\n\nSi vous utilisez un ordinateur professionnel, pensez à configurer le proxy pour que ces commandes puissent fonctionner (voir https://www.book.utilitr.org/01_r_insee/fiche-personnaliser-r#le-fichier-.renviron). Pour cela vous pouvez utiliser curl::ie_get_proxy_for_url() pour récupérer l’adresse du proxy et ajouter deux variable http_proxy et https_proxy dans les variables d’environnement."
  },
  {
    "objectID": "slides.html#introduction",
    "href": "slides.html#introduction",
    "title": "Atelier D2E",
    "section": "Introduction",
    "text": "Introduction\nSur longue période, les institutions, les normes de sociétés ainsi que les comportements des agents économiques évoluent, induisant des changements dans la dynamique des séries économiques étudiées.\n\nDe nombreux modèles de l’Insee sont basés sur des régressions linéaires (CJO, prévisions, calage…) qui supposent que les relations entre les variables sont fixes dans le temps.\n\n\nHypothèse vraie sur le court-terme mais généralement fausse sur le long-terme ou en présence de changements structurels (changement de nomenclature, de définition, COVID…)\n\n\nObjectifs :\n\nétudier des méthodes qui permettent de relâcher cette contrainte ;\nproposer une façon simple d’implémenter et de comparer ces méthodes (package  tvCoef)"
  },
  {
    "objectID": "slides.html#modèle-de-régression-linéaire",
    "href": "slides.html#modèle-de-régression-linéaire",
    "title": "Atelier D2E",
    "section": "Modèle de régression linéaire",
    "text": "Modèle de régression linéaire\nIdée générale :\n\\[\n\\DeclareMathOperator{\\argmin}{argmin}\ny_t=\\beta_0+\\beta_1 x_{1,t}+\\dots+\\beta_p x_{p,t} +\\varepsilon_t\n\\]\n\\[\ny_t=\\beta X_t+\\varepsilon_t\n\\]\nEstimé grâce à la méthode des moindres carrés ordinaires\n\nExemple simple : prévision du PIB à partir du climat des affaires France (au mois 2) en niveau et en différence\n\\[\nPIB_t = \\beta_0 + \\beta_1 climat\\_fr_t + \\beta_2 \\Delta climat\\_fr_t + \\varepsilon_t\n\\]\n\n\nEstimation entre 2000 T1 et 2019 T4 :\n\\[\nPIB_t = -2,09 + 0,02 \\times climat\\_fr_t + 0,04 \\times \\Delta climat\\_fr_t + \\varepsilon_t\n\\]"
  },
  {
    "objectID": "slides.html#section",
    "href": "slides.html#section",
    "title": "Atelier D2E",
    "section": "",
    "text": "Deux types d’estimations : estimations dans l’échantillon et estimations en temps réel.\n\nDans l’échantillon : utilise toutes les données disponibles pour estimer les valeurs au sein de l’échantillon. Ce sont les valeurs ajustées qu’on obtient après une régression linéaire.\n\n\n\nEn temps réel : prévisions hors échantillon qui prévoient des valeurs en dehors d’un échantillon de données.\n Modèle estimé jusqu’à \\(t\\) pour effectuer la prévision de \\(t+1\\), puis on recommence en estimant le modèle jusqu’à \\(t+1\\).\n\n\n\nQualité des modèles évaluée par l’analyse des résidus et le calcul du RMSE (root mean square error) :\n\\[\n\\sqrt{\\frac{\\sum_{t=1}^{T} (PIB_t - \\widehat{PIB}_t)^2}{T}}\n\\]"
  },
  {
    "objectID": "slides.html#objectifs",
    "href": "slides.html#objectifs",
    "title": "Atelier D2E",
    "section": "Objectifs",
    "text": "Objectifs\nComparer différentes méthodes pour modéliser et estimer :\n\\[\nPIB_t = \\beta_{0,t} + \\beta_{1,t} climat\\_fr_t + \\beta_{2,t} \\Delta climat\\_fr_t + \\varepsilon_t\n\\]\nIdée : rester proche du cas de la régression linéaire pour que les résultats restent facilement interprétables.\n\nPlan :\n\nLes tests statistiques étudiés\nLes régressions par morceaux\nLes régressions locales\nLes modèles espace-état\nQuelques résultats généraux"
  },
  {
    "objectID": "slides.html#tests-statistiques-bai-et-perron",
    "href": "slides.html#tests-statistiques-bai-et-perron",
    "title": "Atelier D2E",
    "section": "Tests statistiques : Bai et Perron",
    "text": "Tests statistiques : Bai et Perron\nOn cherche à savoir si les coefficients sont stables au cours du temps.\nBai et Perron s’appuie sur le test de Chow. Proposent un algorithme efficace pour trouver les dates de ruptures (package strucchange). Soit le modèle :\n\\[\nPIB_t = \\beta_0 + \\beta_1 climat\\_fr_t + \\beta_2 \\Delta climat\\_fr_t + \\varepsilon_t\n\\]\n\nOn le sépare en deux, autour d’une date \\(t_1\\), et on obtient deux sous-modèles :\n\\[\n\\forall t \\leq t_1 :\\quad PIB_t = \\beta_0' + \\beta_1' climat\\_fr_t + \\beta_2' \\Delta climat\\_fr_t + \\varepsilon_t\n\\]\n\\[\n\\forall t > t_1 :\\quad PIB_t = \\beta_0'' + \\beta_1'' climat\\_fr_t + \\beta_2'' \\Delta climat\\_fr_t + \\varepsilon_t\n\\]\nL’hypothèse nulle suppose que \\(\\beta_0' = \\beta_0''\\), \\(\\beta_1' = \\beta_1''\\) et \\(\\beta_2' = \\beta_2''\\). Autrement dit, on teste si les deux modèles obtenus sont significativement différents."
  },
  {
    "objectID": "slides.html#limites-de-bai-perron",
    "href": "slides.html#limites-de-bai-perron",
    "title": "Atelier D2E",
    "section": "Limites de Bai Perron",
    "text": "Limites de Bai Perron\n\nLa rupture peut n’être que sur un sous-ensemble de variables, mais le test ne s’applique que sur l’ensemble d’un modèle\n\n\nOn teste :\n\\[\nPIB_t = (\\beta_{0} + \\beta_{1} climat\\_fr_t + \\beta_{2} \\Delta climat\\_fr_t) \\mathbb 1_{t \\leq t_1} +\n\\\\\n(\\beta_{0}' + \\beta_{1}' climat\\_fr_t + \\beta_{2}' \\Delta climat\\_fr_t)\\mathbb 1_{t > t_1} +\n\\varepsilon_t\n\\]\nOn ne peut pas tester :\n\\[\nPIB_t = \\beta_{0} + \\beta_{1} climat\\_fr_t + (\\beta_{2} \\mathbb 1_{t \\leq t_1}+ \\beta_{2}' \\mathbb 1_{t > t_1})\\Delta climat\\_fr_t +\n\\varepsilon_t\n\\]\n\n\n\nInstabilité sur le choix de la date et la rupture n’est pas forcément brutale (ex : évolution lente dans le temps)\n\n\n\nMais ces tests supposent qu’il existe une date de rupture à déterminer, alors que l’on veut parfois juste savoir si les coefficients sont constants ou non."
  },
  {
    "objectID": "slides.html#nyblom-et-hansen",
    "href": "slides.html#nyblom-et-hansen",
    "title": "Atelier D2E",
    "section": "Nyblom et Hansen",
    "text": "Nyblom et Hansen\nTests trouvés dans la littérature autour de Nyblom et Hansen (1992) : sous  tvCoef::hansen.test() \\[\n\\begin{cases}\n(H_0):&\\text{coefficients constants} \\\\\n(H_1):&\\text{coefficients suivent une martingale}\n\\end{cases}\n\\]\n\nLimites de Hansen :\n\nTest de la l’instabilité de la variance (passer par d’autres tests)\nTest joint ne s’applique pas aux indicatrices\nNe s’applique que sur les variables stationnaires\n\n\n\n Comme tout test, ils ont leurs limites, prendre les résultats avec précaution.\nEx : même si le test de Hansen ne détecte pas d’instabilité, le test de Bai et Perron peut néanmoins détecter des ruptures."
  },
  {
    "objectID": "slides.html#régressions-linéaires-par-morceaux",
    "href": "slides.html#régressions-linéaires-par-morceaux",
    "title": "Atelier D2E",
    "section": "Régressions linéaires par morceaux",
    "text": "Régressions linéaires par morceaux\nModèles les plus simples :\n\\[\n\\exists t_1,\\dots,t_{T-1}:\\:\n\\beta_t = \\beta_1\\mathbb 1_{t \\leq t_1} + \\beta_2 \\mathbb 1_{t_1 < t \\leq t_2} + \\dots + \\beta_T \\mathbb 1_{t_{T-1} < t}\n\\]\n\nS’estiment en :\n\nDécoupant les régresseurs (\\(\\mathbb V[\\varepsilon_t]\\) fixe dans le temps)\n tvCoef::piece_reg()\nOu en faisant des régressions linéaires par morceaux (\\(\\mathbb V[\\varepsilon_t]\\) varie par sous-période)\n tvCoef::bp.lms()\n\n\n\n utilisation du cas 1 car donne une seule régression en sortie.\nDans les deux cas estimations de coefficients restent les mêmes. Différences : sur les variances et sur les estimations en temps réel."
  },
  {
    "objectID": "slides.html#section-4",
    "href": "slides.html#section-4",
    "title": "Atelier D2E",
    "section": "",
    "text": "Avantages :\n\nSimples à comprendre et à implémenter\nFacilement combinable avec d’autres types de modèles (régressions locales)\n\n\n Inconvénients :\n\nSuppose l’existence une rupture brutale\nImprécisions dans le choix de la date\n\n\n\nDans le cas de notre modèle exemple, Bai et Perron détecte une rupture en 2011 T1. Le modèle suivant est donc estimé :\n\\[\nPIB_t = (\\beta_{0,t}+ \\beta_{1,t}climat\\_fr_t + \\beta_{2,t} \\Delta climat\\_fr_t) \\mathbb{1} _{t \\leq 2011} +\n\\\\\n(\\beta_{0,t} + \\beta_{1,t} climat\\_fr_t + \\beta_{2,t} \\Delta climat\\_fr_t) 1_{t > 2011} + \\varepsilon_t\n\\]\n\n\nCe qui donne :\n\\[\nPIB_t = (-2,9+ 0,03 \\times climat\\_fr_t + 0,07 \\times \\Delta climat\\_fr_t) \\mathbb{1} _{t \\leq 2011} +\n\\\\\n(-1,04 + 0,01 \\times climat\\_fr_t - 0,01 \\times \\Delta climat\\_fr_t) 1_{t > 2011} + \\varepsilon_t\n\\]"
  },
  {
    "objectID": "slides.html#régressions-locales-fa-brands-r-project-tvreg",
    "href": "slides.html#régressions-locales-fa-brands-r-project-tvreg",
    "title": "Atelier D2E",
    "section": "Régressions locales :  tvreg",
    "text": "Régressions locales :  tvreg\nHypothèse \\(\\beta_t = \\beta(z_t)\\) avec par défaut \\(z_t = t/T\\) et \\(\\beta()\\) localement constante (Nadaraya-Watson) ou localement linéaire.\n\nEstimation : \\[\n\\beta(z_t) = \\underset{\\theta_0}{\\argmin}\\sum_{j=1}^T\\left(y_{j}-x_j\\theta_0\\right)^2K_b(z_j-z_t)\n\\] Avec \\(K_b(x)=\\frac 1 b K(x/b)\\) une fonction de noyau pour pondérer les observations.\n\n\nRemarque :\n\nSi \\(b\\geq1\\) on utilise toutes les données pour chaque estimation.\n\nSi \\(b \\rightarrow 20\\) le poids associé à chaque donnée tend à devenir le même pour toutes, estimation \\(\\simeq\\) à la régression linéaire"
  },
  {
    "objectID": "slides.html#section-8",
    "href": "slides.html#section-8",
    "title": "Atelier D2E",
    "section": "",
    "text": "Inconvénient :\n\nTous les coefficients varient\n\nProblème du choix de \\(b\\) : par validation croisée (entre 0 et 20) mais peu discriminant\n\nFortes révisions possibles en temps-réel : ajout d’un point, changement de b, noyau asymétrique\n\n\nRemarque :\n\nPossibilité de combiner les précédents modèles en estimant une régression locale sur des données coupées\nEn effectuer deux régression, on peut fixer les coefficients de certaines variables."
  },
  {
    "objectID": "slides.html#modèles-espace-état",
    "href": "slides.html#modèles-espace-état",
    "title": "Atelier D2E",
    "section": "Modèles espace-état",
    "text": "Modèles espace-état\nModélisation espace-état est une méthodologie générale qui permet de traiter un grand nombre de problèmes de séries temporelle.\n\nHypothèse : problème déterminé par une série de vecteurs non observés \\(\\alpha_1,\\dots,\\alpha_n\\) associés aux observations \\(y_1,\\dots,y_n\\), la relation entre \\(\\alpha_t\\) et \\(y_t\\) étant spécifiée par le modèle espace-état.\n\n\nPlusieurs formes de modèles sont possibles, les plus simples étant les modèles linéaires gaussiens.\nVersion simplifiée :\n\\[\n\\begin{cases}\ny_t=X_t\\alpha_t+\\varepsilon_t,\\quad&\\varepsilon_t\\sim\\mathcal N(0,\\sigma^2)\\\\\n\\alpha_{t+1}=\\alpha_t+\\eta_t,\\quad&\\eta_t\\sim\\mathcal N(0,\\sigma^2 Q)\n\\end{cases},\\text{ avec }\\eta_t\\text{ et }\\varepsilon_t\\text{ indépendants}\n\\]\navec \\(y_t\\) de dimension \\(p\\times 1\\) vecteur des observations, et \\(\\alpha_t\\) de dimension \\(m \\times 1\\) vecteur d’états (state vector).\n\n\n\\(\\sigma^2\\) un facteur simplifiant les estimations (Concentration of loglikelihood)."
  },
  {
    "objectID": "slides.html#retour-sur-la-régression-linéaire",
    "href": "slides.html#retour-sur-la-régression-linéaire",
    "title": "Atelier D2E",
    "section": "Retour sur la régression linéaire",
    "text": "Retour sur la régression linéaire\nRégression linéaire : \\[\n\\begin{cases}\ny_t=X_t\\alpha+\\varepsilon_t,\\quad&\\varepsilon_t\\sim\\mathcal N(0,\\sigma^2)\\\\\n\\alpha_{t+1}=\\alpha_t=\\dots=\\alpha_0=\\alpha\n\\end{cases}\n\\] C’est-à-dire : \\[\nPIB_t = \\beta_0 + \\beta_1 climat\\_fr_t + \\beta_2 \\Delta climat\\_fr_t + \\varepsilon_t\n\\] Devient : \\[\nPIB_t=\\begin{pmatrix}1 & climat\\_fr & \\Delta climat\\_fr\\end{pmatrix}_t\n\\begin{pmatrix}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\beta_2\n\\end{pmatrix} + \\varepsilon_t\n\\]"
  },
  {
    "objectID": "slides.html#estimation-par-filtre-de-kalman",
    "href": "slides.html#estimation-par-filtre-de-kalman",
    "title": "Atelier D2E",
    "section": "Estimation par filtre de Kalman",
    "text": "Estimation par filtre de Kalman\nDeux opérations classiques : filtering et smoothing\n\nSmoothing : estime le coefficient à chaque date grâce à toute l’information disponible. Ce qui est proche des estimations dans l’échantillon.\n\n\\[\n\\hat\\alpha_t = E[\\alpha_t|y_0, \\dots, y_n]\n\\] Ex : régression linéaire : \\(\\hat\\alpha_t = \\hat \\alpha\\)\n\n\nFiltering : estime le coefficient suivant (en \\(t+1\\)) avec les informations connues en \\(t\\). Ce qui est proche des estimations en temps-réel.\n\n\\[\na_{t+1} = E[\\alpha_{t+1}|y_0, \\dots, y_t]\n\\]\nEx : régression linéaire : \\(a_{2010T2} = \\hat \\alpha\\) estimé en utilisant les données jusqu’en 2010T1"
  },
  {
    "objectID": "slides.html#résultats",
    "href": "slides.html#résultats",
    "title": "Atelier D2E",
    "section": "Résultats",
    "text": "Résultats\nEtude de 25 modèles de prévision de la production manufacturière estimés entre 1990 T1 et 2019 T4. On estime les différents modèles présentés dans l’échantillon et en temps réel, puis on compare les RMSE des modèles par rapport au modèle linéaire. Enfin on fait des moyennes par secteur.\n\nOn obtient les résultats suivants pour les estimations dans l’échantillon :\n\n\n\n\n \n  \n      \n    Reg linéaire \n    Espace état \n    Reg morceaux \n    Reg locale + morceaux \n    Reg locale \n  \n \n\n  \n    model_c1 (7) \n    1 \n    0,97 \n    1,00 \n    1,00 \n    1,00 \n  \n  \n    model_c3 (5) \n    1 \n    0,85 \n    0,93 \n    0,90 \n    0,94 \n  \n  \n    model_c4 (5) \n    1 \n    0,81 \n    0,96 \n    0,90 \n    0,90 \n  \n  \n    model_c5 (5) \n    1 \n    0,75 \n    0,80 \n    0,78 \n    0,78 \n  \n  \n    model_manuf (3) \n    1 \n    0,96 \n    0,99 \n    0,97 \n    0,98 \n  \n\n\n\n\n\n\n\nLa plupart des modèles sont généralement meilleurs que le modèle linéaire."
  },
  {
    "objectID": "slides.html#section-15",
    "href": "slides.html#section-15",
    "title": "Atelier D2E",
    "section": "",
    "text": "Et en temps réel :\n\n\n\n\n \n  \n      \n    Reg linéaire \n    Espace état \n    Reg morceaux \n    Reg locale + morceaux \n    Reg locale \n  \n \n\n  \n    model_c1 (7) \n    1 \n    0,99 \n    1,00 \n    1,00 \n    1,00 \n  \n  \n    model_c3 (5) \n    1 \n    0,91 \n    2,73 \n    2,74 \n    0,99 \n  \n  \n    model_c4 (5) \n    1 \n    0,92 \n    5,13 \n    5,19 \n    1,06 \n  \n  \n    model_c5 (5) \n    1 \n    0,87 \n    2,58 \n    2,75 \n    1,26 \n  \n  \n    model_manuf (3) \n    1 \n    0,96 \n    1,01 \n    1,03 \n    1,00 \n  \n\n\n\n\n\n\nLes modèles espace-état sont meilleurs que le modèle linéaire en terme de RMSE pour la prévision en temps réel. Pour ce qui est des autres modèles, plus variable d’un modèle à l’autre."
  },
  {
    "objectID": "slides.html#conclusion",
    "href": "slides.html#conclusion",
    "title": "Atelier D2E",
    "section": "Conclusion",
    "text": "Conclusion\n\nDe nombreux modèles peuvent être estimés autour des régressions linéaires : le cadre reste simple mais la modélisation est plus complexe\n choix de modélisations doivent être faits\n\n\n\nMême s’ils peuvent améliorer les performances des modèles « classiques » ils ne les remplacent pas pour autant\n\n\n\n\nModèles parfois complexes à implémenter (notamment espace-état)\n tvCoef peut vous aider (https://github.com/AQLT/tvCoef)"
  },
  {
    "objectID": "slides.html#à-venir",
    "href": "slides.html#à-venir",
    "title": "Atelier D2E",
    "section": "À venir",
    "text": "À venir\nCourt-terme : pause de 10/15 minutes suivie d’un atelier pratique :\nhttps://aqlt.github.io/AteliertvCoef/\nSur tvCoef : documentation, gestion des retards de la variable endogène, amélioration des estimations en temps réel autour de la date de rupture des régressions par morceaux\nAutour cette l’étude : séminaire D2E + document de travail\nAutres études : analyse de ces méthodes pour la CJO"
  },
  {
    "objectID": "TP.html",
    "href": "TP.html",
    "title": "Utilisation de modèles de régression à coefficients variant dans le temps pour la prévision conjoncturelle",
    "section": "",
    "text": "L’objectif de ce TP est d’apprendre à utiliser quelques fonctionnalités du package tvCoef pour l’estimation de modèles de régression à coefficients variant dans le temps.\n\nLes packages suivants seront utilisés :\n\npackages_to_install <- c(\"dygraphs\", \"car\", \"dynlm\")\n\npackages <- installed.packages()[,\"Package\"][! packages_to_install %in% installed.packages()[,\"Package\"]]\nif (length(packages) > 0) {\n    install.packages(packages)\n}\nif (\"tvCoef\" %in% installed.packages()[,\"Package\"]) {\n  remotes::install_github(\"palatej/rjd3toolkit\")\n  remotes::install_github(\"palatej/rjd3sts\")\n  remotes::install_github(\"AQLT/tvCoef\")\n}\n\nPour l’installation de tvCoef, voir le manuel d’installation. Si vous utiliser le https://datalab.ssp.cloud.fr, créer une instance en cliquant ici : .\nPour ce TP nous utiliserons les données de la base tvCoef::manufacturingpour prévoir l’évolution trimestrielle de la production du secteur des autres industries manufacturières (C5, prod_c5) à partir de :\n\nl’acquis de croissance au premier mois du trimestre de l’indice de production industrielle du même secteur (overhang_ipi1_c5) ;\ndes soldes d’opinion de l’Insee et de la Banque de France. Ces soldes d’opinion sont trimestrialisés en prenant la place du mois dans le trimestre :\n\ninsee_bc_c5_m3 : climat des affaires au 3e mois du trimestre (mars, juin, septembre, décembre)\ninsee_oscd_c5_m2 : niveau des carnets de commandes au 2e mois du trimestre (février, mai, septembre, novembre)\ninsee_tppre_c5_m3 : solde d’opinion sur l’évolution future de la production au 3e mois du trimestre (février, mai, septembre, novembre).\nbdf_tuc_c5_m2 : taux d’utilisation des capacités de production au deuxième mois du trimestre (février, mai, septembre, novembre).\n\n\nLes deux dernières variables sont utilisées en différence.\nPar simplification, nous estimerons ici le modèle entre le 1993T1 et 2019T4 : pour estimer le modèle au-delà cette date, il faudrait ajouter des indicatrices au cours de l’année 2020 et vérifier si le modèle estimé est toujours bien spécifié.\nLe modèle peut alors être estimé en utilisant par exemple la fonction dynlm::dynlm()1 :\n\nlibrary(tvCoef)\nlibrary(dynlm)\ndata <- window(manufacturing, start = 1993, end = c(2019, 4))\ny <- data[, \"prod_c5\"]\nmodel_c5 <- dynlm(\n  formula = prod_c5 ~ overhang_ipi1_c5 + insee_bc_c5_m3 + insee_oscd_c5_m2\n  + diff(insee_tppre_c5_m3, 1) + diff(bdf_tuc_c5_m2, 1),\n  data = data\n)\nmodel_c5\n\n\nTime series regression with \"ts\" data:\nStart = 1993(2), End = 2019(4)\n\nCall:\ndynlm(formula = prod_c5 ~ overhang_ipi1_c5 + insee_bc_c5_m3 + \n    insee_oscd_c5_m2 + diff(insee_tppre_c5_m3, 1) + diff(bdf_tuc_c5_m2, \n    1), data = data)\n\nCoefficients:\n               (Intercept)            overhang_ipi1_c5  \n                 -6.383023                    0.102405  \n            insee_bc_c5_m3            insee_oscd_c5_m2  \n                  0.061437                   -0.005596  \ndiff(insee_tppre_c5_m3, 1)      diff(bdf_tuc_c5_m2, 1)  \n                  0.039043                    0.397070  \n\n\nLes prévisions dans l’échantillon (in sample) peuvent être extraites avec les fonctions fitted() ou predict() et les prévisions en temps-réel (out of sample) avec la fonction tvCoef::oos_prev().\nPour évaluer la qualité en temps-réel, nous utiliserons les résidus à partir de 2000 :\n\nprev_oos_lm <- oos_prev(model_c5)\nres_lm_is <- residuals(model_c5)\nres_lm_oos <- prev_oos_lm$residuals\nrmse_lm <- c(IS = rmse(res_lm_is), OOS = rmse(res_lm_oos))\nrmse_lm\n\n       IS       OOS \n0.6990756 0.8494077 \n\n\nPour tracer les prévisions, on peut utiliser la fonction plot() :\n\nplot(window(y, start = 2000))\nlines(prev_oos_lm$prevision, col = \"red\")\nlegend(\"bottomleft\", legend = c(\"y\",\"Prev. temps réel\"),\n       col= c(\"black\", \"red\"), lty = 1)\n\n\n\n\n\n1 Régression par morceaux\nPour utiliser la régression par morceaux, la première étape est d’analyser les potentielles dates de rupture. Pour cela nous utiliserons la fonction tvCoef::piece_reg() (qui s’appuie sur le package strucchange, voir ?strucchange::breakpoints() pour plus d’informations).\n\n\n\n\n\n\nExercice\n\n\n\nUtiliser la fonction tvCoef::piece_reg() sur le modèle précédent et regarder les résultats : y a-t-il des dates de ruptures ? Peuvent-elles être interprétées ?\nEn utilisant notamment oos_prev(), comparer la qualité prédictive des modèles.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nreg_morceaux <- piece_reg(model_c5)\n# Ici une date de rupture\n# Si pas de rupture détectée, le modèle renvoyé est le modèle initial\nreg_morceaux \n\n$model\n\nTime series regression with \"ts\" data:\nStart = 1993(2), End = 2019(4)\n\nCall:\ndynlm::dynlm(formula = as.formula(formula), data = data2)\n\nCoefficients:\n               `(Intercept)_2008.75`              overhang_ipi1_c5_2008.75  \n                             1.70092                               0.10847  \n              insee_bc_c5_m3_2008.75              insee_oscd_c5_m2_2008.75  \n                            -0.01335                               0.03653  \n`diff(insee_tppre_c5_m3, 1)_2008.75`      `diff(bdf_tuc_c5_m2, 1)_2008.75`  \n                             0.04306                               0.48388  \n               `(Intercept)_2019.75`              overhang_ipi1_c5_2019.75  \n                           -11.60377                               0.47441  \n              insee_bc_c5_m3_2019.75              insee_oscd_c5_m2_2019.75  \n                             0.10798                              -0.03376  \n`diff(insee_tppre_c5_m3, 1)_2019.75`      `diff(bdf_tuc_c5_m2, 1)_2019.75`  \n                             0.03414                               0.18874  \n\n\n$start\n[1] 1993    2\n\n$end\n[1] 2019    4\n\n$frequency\n[1] 4\n\n$breakdates\n[1] 2008.75\n\n$tvlm\n[1] FALSE\n\nattr(,\"class\")\n[1] \"piecereg\"\n\n\nL’objet précédent est une liste qui contient différentes informations, notamment :\n\nmodel : le modèle dynlm estimé ;\nbreakdates : la date de rupture : 2008T4.\n\nAnalysons maintenant les erreurs de prévision :\n\nprev_oos_rm <- oos_prev(reg_morceaux)\nres_rm_is <- residuals(reg_morceaux$model)\nres_rm_oos <- prev_oos_rm$residuals\nstart(res_rm_oos) # Commence en 2000 T2\n\n[1] 2000    2\n\nrmse_rm <- c(IS = rmse(res_rm_is), OOS = rmse(res_rm_oos))\nrbind(rmse_lm, rmse_rm)\n\n               IS       OOS\nrmse_lm 0.6990756 0.8494077\nrmse_rm 0.5731039 1.3826525\n\n\nElle sont ici réduites dans l’échantillon mais augmentent en temps réel ! En regardant plus précisément, cela vient d’erreurs élevées autour de la date de rupture car l’estimation n’est pas suffisamment robuste !\n\nplot(res_rm_oos, col = \"red\", main = \"Résidus en temps-réel\")\nlines(res_lm_oos, col = \"black\")\nlegend(\"topleft\", legend = c(\"LM\",\"Reg. par morceaux\"),\n       col= c(\"black\", \"red\"), lty = 1)\n\n\n\n\nEn analysant les prévisions à partir de 2010, les erreurs sont réduites par rapport à précédemment mais restent plus élevées que celles de la régression linéaire :\n\napply(window(ts.union(res_lm_oos, res_rm_oos), start = 2010), 2, rmse)\n\nres_lm_oos res_rm_oos \n 0.7863127  1.1067406 \n\n\n\n\n\n\n\n\n\n\n\nExercice\n\n\n\nLe modèle précédent suppose une rupture sur toutes les variables : est-ce réaliste dans ce cas ? Appliquer la fonction tvCoef::hansen.test() sur votre modèle et interpréter les résultats.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nhansen.test(model_c5)\n\n\nVariable                  L        Stat     Conclusion \n______________________________________________________________ \n(Intercept)                  0.2561   0.47   FALSE   \noverhang_ipi1_c5             0.8564   0.47    TRUE   \ninsee_bc_c5_m3               0.2708   0.47   FALSE   \ninsee_oscd_c5_m2             0.1508   0.47   FALSE   \ndiff(insee_tppre_c5_m3, 1)   0.2568   0.47   FALSE   \ndiff(bdf_tuc_c5_m2, 1)       0.1533   0.47   FALSE   \nVariance                     0.4562   0.47   FALSE   \nJoint Lc                     1.6516   2.11   FALSE   \n\n\nLecture: True means reject H0 at level 5% \n\n\nLe test de Hansen conclut que seul l’acquis d’IPI évolue. Attention à l’interprétation du test sur la constante : si cette variable évolue il est possible que la constante aussi.\nOn peut également faire des tests de Fisher sur le modèle précédent pour tester si les coefficients sont égaux entre les sous-périodes. Cela peut être fait avec la fonction car::linearHypothesis() :\n\n# on rejette H0 => non constance des coefficients\ncar::linearHypothesis(reg_morceaux$model, \"`(Intercept)_2008.75` = `(Intercept)_2019.75`\")\n\nLinear hypothesis test\n\nHypothesis:\n(Intercept)_2008.75` - Intercept)_2019.75` = 0\n\nModel 1: restricted model\nModel 2: y ~ 0 + (`(Intercept)_2008.75` + overhang_ipi1_c5_2008.75 + insee_bc_c5_m3_2008.75 + \n    insee_oscd_c5_m2_2008.75 + `diff(insee_tppre_c5_m3, 1)_2008.75` + \n    `diff(bdf_tuc_c5_m2, 1)_2008.75` + `(Intercept)_2019.75` + \n    overhang_ipi1_c5_2019.75 + insee_bc_c5_m3_2019.75 + insee_oscd_c5_m2_2019.75 + \n    `diff(insee_tppre_c5_m3, 1)_2019.75` + `diff(bdf_tuc_c5_m2, 1)_2019.75`)\n\n  Res.Df    RSS Df Sum of Sq      F  Pr(>F)  \n1     96 37.058                              \n2     95 35.144  1    1.9145 5.1751 0.02516 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# on rejette H0 => non constance des coefficients\ncar::linearHypothesis(reg_morceaux$model, \"overhang_ipi1_c5_2019.75 = overhang_ipi1_c5_2008.75\")\n\nLinear hypothesis test\n\nHypothesis:\n- overhang_ipi1_c5_2008.75  + overhang_ipi1_c5_2019.75 = 0\n\nModel 1: restricted model\nModel 2: y ~ 0 + (`(Intercept)_2008.75` + overhang_ipi1_c5_2008.75 + insee_bc_c5_m3_2008.75 + \n    insee_oscd_c5_m2_2008.75 + `diff(insee_tppre_c5_m3, 1)_2008.75` + \n    `diff(bdf_tuc_c5_m2, 1)_2008.75` + `(Intercept)_2019.75` + \n    overhang_ipi1_c5_2019.75 + insee_bc_c5_m3_2019.75 + insee_oscd_c5_m2_2019.75 + \n    `diff(insee_tppre_c5_m3, 1)_2019.75` + `diff(bdf_tuc_c5_m2, 1)_2019.75`)\n\n  Res.Df    RSS Df Sum of Sq      F    Pr(>F)    \n1     96 44.941                                  \n2     95 35.144  1    9.7974 26.484 1.429e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# on ne rejette pas H0 => constance des coefficients\ncar::linearHypothesis(reg_morceaux$model, \"`diff(insee_tppre_c5_m3, 1)_2019.75` = `diff(insee_tppre_c5_m3, 1)_2008.75`\")\n\nLinear hypothesis test\n\nHypothesis:\n- diff(insee_tppre_c5_m3,_2008.75`  + diff(insee_tppre_c5_m3,_2019.75` = 0\n\nModel 1: restricted model\nModel 2: y ~ 0 + (`(Intercept)_2008.75` + overhang_ipi1_c5_2008.75 + insee_bc_c5_m3_2008.75 + \n    insee_oscd_c5_m2_2008.75 + `diff(insee_tppre_c5_m3, 1)_2008.75` + \n    `diff(bdf_tuc_c5_m2, 1)_2008.75` + `(Intercept)_2019.75` + \n    overhang_ipi1_c5_2019.75 + insee_bc_c5_m3_2019.75 + insee_oscd_c5_m2_2019.75 + \n    `diff(insee_tppre_c5_m3, 1)_2019.75` + `diff(bdf_tuc_c5_m2, 1)_2019.75`)\n\n  Res.Df    RSS Df Sum of Sq      F Pr(>F)\n1     96 35.201                           \n2     95 35.144  1  0.056906 0.1538 0.6958\n\n\n\n\n\n\n\n\n\n\n\nExercice\n\n\n\nEn exploitant les résultats de l’exercice précédent, simplifier le modèle de régression par morceaux.\nOn pourra pour cela utiliser le paramètre fixed_var de piece_reg() pour fixer certaines variables (i.e. : ne pas découper les régresseurs).\nComparer les prévisions avec les modèles précédents.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nIci nous allons fixer toutes les variables sauf les deux premières (constante + acquis d’IPI – overhang)\n\nreg_morceaux2 <- piece_reg(model_c5, fixed_var = c(3, 4, 5, 6))\n\n# Rmq : la date de rupture est détectée sur le modèle complet et non\n#  sur le sous-modèle avec des variables fixes\nreg_morceaux2 \n\n$model\n\nTime series regression with \"ts\" data:\nStart = 1993(2), End = 2019(4)\n\nCall:\ndynlm::dynlm(formula = as.formula(formula), data = data2)\n\nCoefficients:\n              insee_bc_c5_m3              insee_oscd_c5_m2  \n                    0.042179                      0.005864  \n`diff(insee_tppre_c5_m3, 1)`      `diff(bdf_tuc_c5_m2, 1)`  \n                    0.042554                      0.331692  \n       `(Intercept)_2008.75`      overhang_ipi1_c5_2008.75  \n                   -4.386765                      0.106947  \n       `(Intercept)_2019.75`      overhang_ipi1_c5_2019.75  \n                   -4.152134                      0.443726  \n\n\n$start\n[1] 1993    2\n\n$end\n[1] 2019    4\n\n$frequency\n[1] 4\n\n$breakdates\n[1] 2008.75\n\n$tvlm\n[1] FALSE\n\nattr(,\"class\")\n[1] \"piecereg\"\n\nprev_oos_rm2 <- oos_prev(reg_morceaux2)\nres_rm2_is <- residuals(reg_morceaux2$model)\nres_rm2_oos <- prev_oos_rm2$residuals\nrmse_rm2 <- c(IS = rmse(res_rm2_is), OOS = rmse(res_rm2_oos))\nrbind(rmse_lm, rmse_rm, rmse_rm2)\n\n                IS       OOS\nrmse_lm  0.6990756 0.8494077\nrmse_rm  0.5731039 1.3826525\nrmse_rm2 0.6003532 0.8747103\n\n# Après 2010\napply(window(ts.union(res_lm_oos, res_rm_oos, res_rm2_oos), start = 2010), 2, rmse)\n\n res_lm_oos  res_rm_oos res_rm2_oos \n  0.7863127   1.1067406   0.7050171 \n\n\nCela permet d’améliorer la qualité de la prévision en temps-réel mais pas celle dans l’échantillon.\n\n\n\n\n\n2 Régression locale\nPour rappel, la régression locale revient, pour chaque date \\(t\\) à estimer \\(\\beta_t\\)\n\\[\n\\DeclareMathOperator{\\argmin}{argmin}\n\\hat \\beta = \\underset{\\theta_0}{\\argmin}\\sum_{j=1}^T\\left(y_{j}-x_j\\theta_0\\right)^2K_b\\left(\\frac{j-t}{T}\\right)\n\\]\nDans le package ici utilisé (tvReg), le noyau utilisé par défaut est le noyau tricube :\n\\[\nK(x)=\\frac{35}{32}\\left(\n  1-\n  \\left\\lvert\n  x\n  \\right\\lvert^2\n\\right)^3 \\mathbb 1_{|x| \\leq 1}\n\\text{ et }\nK_b(x)=\\frac 1 b K(x/b)\n\\]\nPour estimer le modèle, nous utilisons la fonction tvReg::tvLM dont le premier paramètre est une formule. Mais contrairement à dynlm, tvLM ne gère pas directement les variables en différence :\n\nlibrary(tvReg)\ntvReg::tvLM(formula = prod_c5 ~ overhang_ipi1_c5 + insee_bc_c5_m3 + insee_oscd_c5_m2\n  + diff(insee_tppre_c5_m3, 1) + diff(bdf_tuc_c5_m2, 1),\n  data = data)\n\nError in model.frame.default(formula = prod_c5 ~ overhang_ipi1_c5 + insee_bc_c5_m3 + : les longueurs des variables diffèrent (trouvé pour 'diff(insee_tppre_c5_m3, 1)')\n\n\nPour éviter les problèmes liées au variables en différence, nous récupérons les données transformées de dynlm en utilisant la fonction tvCoef::get_data(model_c5), ce qui permet également de simplifier la formule en prod_c5 ~ .(puisque la base de données alors utilisée ne contient que les exogènes utiles).\n\n\n\n\n\n\nExercice\n\n\n\nEstimer le modèle en utilisant les indications précédentes.\nQuelle fenêtre est utilisée (paramètre \\(b\\)) ? Est-ce que les résultats sont différents de ceux de la régression linéaire ? Tracer les coefficients obtenus à chaque date (fonction coef() pour les extraire, il faudrait reconvertir le résultat en objet ts())\nComparer les erreurs de prévision dans l’échantillon avec ceux des modèles précédents.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLa fenêtre retenue est de 0,31 : les résultats seront donc différents de ceux de la régression linéaire.\n\ntvlm <- tvReg::tvLM(formula = prod_c5 ~ .,\n                 data = get_data(model_c5))\n\nCalculating regression bandwidth... bw =  0.4698719 \n\ncoefs_tvlm <- ts(coef(tvlm), end = end(data), frequency = frequency(data))\nplot(coefs_tvlm)\n\n\n\n\nIci toutes les coefficients sont variables alors que certains pourraient être fixes comme vu dans la partie précédente. Pour fixer certaines variables, on pourrait faire une régression en deux étapes.\n\nres_tvlm_is <- residuals(tvlm)\nrmse_tvlm <- c(IS = rmse(res_tvlm_is), OOS = NA)\nrbind(rmse_lm, rmse_rm, rmse_rm2, rmse_tvlm)\n\n                 IS       OOS\nrmse_lm   0.6990756 0.8494077\nrmse_rm   0.5731039 1.3826525\nrmse_rm2  0.6003532 0.8747103\nrmse_tvlm 0.5971192        NA\n\n\nLe RMSE dans l’échantillon est réduit.\n\n\n\n\n\n\n\n\n\nExercice\n\n\n\nL’objectif de cet exercice est de calculer les prévisions hors échantillon.\nAppliquer la fonction tvCoef::oos_prev() au modèle précédent avec les paramètres end = end(data), frequency = frequency(data) (utiles pour garder la structure temporelle des données) : quels sont les paramètres réestimés ?\nAppliquer maintenant la même fonction avec le paramètre fixed_bw = TRUE. À quoi cela correspond ? Comparer les erreurs de prévisions obtenus.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nDans les modèles de régression locales, il y a deux sources de révisions en temps-réel :\n\nActualisation des coefficients du fait de l’ajout de nouveaux points (noyau asymétrique utilisé pour les premières estimations)\nActualisation de la fenêtre.\n\n\n\n\n\n\n\nActualisation de la fenêtre et des coefficients\n\n\n\nPar défaut, avec oos_prev() tous les paramètres sont réestimés. C’est en particulier le cas de la fenêtre qui est réestimée à chaque date, à chaque observation :\n\nprev_oos_tvlm_all <- oos_prev(tvlm, end = end(data), frequency = frequency(data))\n\nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  20 \nCalculating regression bandwidth... bw =  1.419831 \nCalculating regression bandwidth... bw =  2.82952 \nCalculating regression bandwidth... bw =  1.223547 \nCalculating regression bandwidth... bw =  1.170575 \nCalculating regression bandwidth... bw =  1.15924 \nCalculating regression bandwidth... bw =  1.149263 \nCalculating regression bandwidth... bw =  1.042411 \nCalculating regression bandwidth... bw =  0.9797272 \nCalculating regression bandwidth... bw =  0.4014617 \nCalculating regression bandwidth... bw =  0.8781985 \nCalculating regression bandwidth... bw =  0.4896312 \nCalculating regression bandwidth... bw =  0.491814 \nCalculating regression bandwidth... bw =  0.504626 \nCalculating regression bandwidth... bw =  0.4866928 \nCalculating regression bandwidth... bw =  0.3382399 \nCalculating regression bandwidth... bw =  0.4753745 \nCalculating regression bandwidth... bw =  0.4747202 \nCalculating regression bandwidth... bw =  0.478007 \nCalculating regression bandwidth... bw =  0.4662297 \nCalculating regression bandwidth... bw =  0.4636153 \nCalculating regression bandwidth... bw =  0.7847365 \nCalculating regression bandwidth... bw =  0.7712849 \nCalculating regression bandwidth... bw =  0.4601159 \nCalculating regression bandwidth... bw =  0.4618806 \nCalculating regression bandwidth... bw =  0.4630616 \nCalculating regression bandwidth... bw =  0.4480051 \nCalculating regression bandwidth... bw =  0.4333001 \nCalculating regression bandwidth... bw =  0.4067395 \nCalculating regression bandwidth... bw =  0.7120287 \nCalculating regression bandwidth... bw =  0.7082321 \nCalculating regression bandwidth... bw =  0.3906645 \nCalculating regression bandwidth... bw =  0.3970553 \nCalculating regression bandwidth... bw =  0.3421958 \nCalculating regression bandwidth... bw =  0.3365896 \nCalculating regression bandwidth... bw =  0.329112 \nCalculating regression bandwidth... bw =  0.3323843 \nCalculating regression bandwidth... bw =  0.649492 \nCalculating regression bandwidth... bw =  0.4963082 \nCalculating regression bandwidth... bw =  0.552225 \nCalculating regression bandwidth... bw =  0.6002736 \nCalculating regression bandwidth... bw =  0.5783915 \nCalculating regression bandwidth... bw =  0.4433933 \nCalculating regression bandwidth... bw =  0.4365778 \nCalculating regression bandwidth... bw =  0.4698719 \n\nall_bw <- ts(sapply(prev_oos_tvlm_all$model, `[[`, \"bw\"),\n             end = end(prev_oos_tvlm_all$prevision),\n             frequency = frequency(data))\nplot(all_bw)\n\n\n\nres_tvlm_all_oos <- prev_oos_tvlm_all$residuals\nrmse_tvlm[\"OOS\"] <- rmse(res_tvlm_all_oos)\nrbind(rmse_lm, rmse_rm, rmse_rm2, rmse_tvlm)\n\n                 IS       OOS\nrmse_lm   0.6990756 0.8494077\nrmse_rm   0.5731039 1.3826525\nrmse_rm2  0.6003532 0.8747103\nrmse_tvlm 0.5971192 0.8595945\n\n# Après 2010\napply(window(ts.union(res_lm_oos, res_rm_oos, res_rm2_oos, res_tvlm_all_oos), start = 2010), 2, rmse)\n\n      res_lm_oos       res_rm_oos      res_rm2_oos res_tvlm_all_oos \n       0.7863127        1.1067406        0.7050171        0.8075138 \n\n\n\n\n\n\n\n\n\n\nActualisation des coefficients uniquement\n\n\n\nFixons maintenant la fenêtre à la dernière valeur estimée :\n\nprev_oos_tvlm_lastbw <- oos_prev(tvlm, end = end(data), frequency = frequency(data),fixed_bw = TRUE)\nres_tvlm_lastbw_oos <- prev_oos_tvlm_lastbw$residuals\nrmse_tvlm[\"OOS\"] <- rmse(res_tvlm_lastbw_oos)\nrbind(rmse_lm, rmse_rm, rmse_rm2, rmse_tvlm)\n\n                 IS       OOS\nrmse_lm   0.6990756 0.8494077\nrmse_rm   0.5731039 1.3826525\nrmse_rm2  0.6003532 0.8747103\nrmse_tvlm 0.5971192 0.9799976\n\n# Après 2010\napply(window(ts.union(res_lm_oos, res_rm_oos, res_rm2_oos, res_tvlm_all_oos, res_tvlm_lastbw_oos), start = 2010), 2, rmse)\n\n         res_lm_oos          res_rm_oos         res_rm2_oos    res_tvlm_all_oos \n          0.7863127           1.1067406           0.7050171           0.8075138 \nres_tvlm_lastbw_oos \n          0.7231632 \n\n\nLe RMSE en temps-réel est réduit par rapport à précédemment mais il reste plus élevé qu’avec la régression linéaire.\n\n\n\n\n\n\n\n\n\n\n\nRemarque\n\n\n\nPour fixer certaines variables, on pourrait faire une régression en deux étapes. La fonction rmse_prev() permet de calculer les prévisions dans l’échantillon et hors échantillon sur le modèle de régression linéaire, la régression par morceaux, la régression locale en fixant ou non certains coefficients.\n\ncomp_prev <- rmse_prev(model_c5, fixed_var = c(3, 4, 5, 6), fixed_bw = TRUE)\n\nCalculating regression bandwidth... bw =  0.4698719 \nCalculating regression bandwidth... bw =  0.3501963 \n\ncomp_prev\n\n                       RMSE_in_sample RMSE_out_of_sample\nlm                          0.6990756          0.8494077\npiece_lm                    0.5731039          1.3826525\npiece_lm fixed coeff        0.6003532          0.8747103\nTvLM                        0.5971192          0.9799976\npiece_tvlm                  0.5354897          1.4605933\npiece_tvlm fixed coeff      0.5470547          1.0154322\nTvLM fixed coeff            0.6254196          0.8574867\n\n\nSept modèles différents sont estimés, dans l’ordre :\n\nModèle de régression linéaire.\nRégression linéaire par morceaux où toutes les variables divisées en fonction de la date de rupture.\nRégression linéaire par morceaux où toutes les variables, sauf celles spécifiées par fixed_var, sont divisées en fonction de la date de rupture.\nRégression locale.\nRégression locale avec toutes les variables divisées en fonction de la date de rupture.\nRégression locale où toutes les variables, sauf celles spécifiées par fixed_var, sont divisées en fonction de la date de rupture.\nRégression locale où les variables celles spécifiées par fixed_var sont estimées par une régression linéaire (coefficients fixes sur l’ensemble de la période).\n\nOn peut ensuite récupérer tous les résidus en temps réel :\n\ncomp_prev_tr <- do.call(cbind, lapply(comp_prev$prevision, `[[`, \"residuals\"))\napply(window(comp_prev_tr, start = 2010), 2, rmse)\n\n             prev_lm        prev_piece_lm   prev_piece_lm_fixe \n           0.7863127            1.1067406            0.7050171 \n           prev_tvlm      prev_piece_tvlm prev_piece_tvlm_fixe \n           0.7231632            1.0894378            0.7072981 \n      prev_tvlm_fixe \n           0.7246941 \n\n\n\n\n\n\n3 Modèles espace-état\nDans cette dernière partie nous estimons un modèle espace-état avec coefficients qui varient dans le temps.\nPour rappel, puisque nous avons 6 variables exogènes, le modèle s’écrit :\n\\[\n\\begin{cases}\ny_t=X_t\\alpha_t+\\varepsilon_t,\\quad&\\varepsilon_t\\sim\\mathcal N(0,\\sigma^2)\\\\\n\\alpha_{t+1}=\\alpha_t+\\eta_t,\\quad&\\eta_t\\sim\\mathcal N(0,\\sigma^2 Q)\n\\end{cases},\\text{ avec }\\eta_t\\text{ et }\\varepsilon_t\\text{ indépendants et }\nQ = \\begin{pmatrix}q_1 &  &0 \\\\ & \\ddots \\\\ 0 & & q_6 \\end{pmatrix}\n\\]\nLa matrice \\(Q\\) peut-être imposée par l’utilisateur (par exemple variance nulle si l’on veut fixer tous les coefficients) ou estimée.\nIl y a également deux opérations classiques :\n\nsmoothing : estimation de \\(\\hat\\alpha_t=E[\\alpha_t|y]\\) et \\(V_t=V[\\alpha_t-\\hat\\alpha_t]=V[\\alpha_t|y]\\) : coefficients et variances estimés en utilisant l’ensemble des données disponibles ;\nfiltering : estimation de \\(a_{t+1}=E[\\alpha_{t+1}|Y_t]\\) et \\(P_{t+1}=V[\\alpha_{t+1}|Y_t]\\) : coefficients et variances estimés de manière dynamique en utilisant l’information disponible jusqu’à la date précédente (estimation en temps-réel).\n\nPour estimer ces modèles nous utiliserons la fonction tvCoef::ssm_lm() dont le premier paramètre est un modèle de régression linéaire (le modèle model_c5).\n\n\n\n\n\n\nExercice\n\n\n\nPar défaut, tvCoef::ssm_lm() estime le modèle en forçant \\(q_1=q_2=\\dots=q_6=0\\). Quel modèle retrouve-t-on ? Regarder les résultats de cette fonction et interpréter les quantités de \"smoothed_states\", \"filtering_states\",\"smoothed_stdev\" (sauf dernière colonne).\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLe modèle estimé est le modèle de régression linéaire !\nLa composante smoothed_states contient les coefficients du modèle de régression linéaire estimé en utilisant toutes les données. La dernière colonne (\"noise\") contient les résidus. La composante smoothed_stdev contient les écart-types associés aux différents coefficients, la dernière colonne s’interprète de manière plus complexe et ne sera pas détaillée ici.\n\nmod_ssm <- ssm_lm(model_c5)\nsummary(model_c5)\n\n\nTime series regression with \"ts\" data:\nStart = 1993(2), End = 2019(4)\n\nCall:\ndynlm(formula = prod_c5 ~ overhang_ipi1_c5 + insee_bc_c5_m3 + \n    insee_oscd_c5_m2 + diff(insee_tppre_c5_m3, 1) + diff(bdf_tuc_c5_m2, \n    1), data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.3241 -0.4566  0.0140  0.4495  1.6115 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                -6.383023   3.213333  -1.986  0.04970 *  \noverhang_ipi1_c5            0.102405   0.022681   4.515 1.72e-05 ***\ninsee_bc_c5_m3              0.061437   0.029218   2.103  0.03797 *  \ninsee_oscd_c5_m2           -0.005596   0.015019  -0.373  0.71021    \ndiff(insee_tppre_c5_m3, 1)  0.039043   0.012029   3.246  0.00159 ** \ndiff(bdf_tuc_c5_m2, 1)      0.397070   0.077580   5.118 1.48e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.7195 on 101 degrees of freedom\nMultiple R-squared:  0.7155,    Adjusted R-squared:  0.7014 \nF-statistic: 50.79 on 5 and 101 DF,  p-value: < 2.2e-16\n\ntail(mod_ssm$smoothed_states, 3)\n\n       (Intercept) overhang_ipi1_c5 insee_bc_c5_m3 insee_oscd_c5_m2\n[105,]   -6.383023        0.1024052     0.06143715     -0.005596399\n[106,]   -6.383023        0.1024052     0.06143715     -0.005596399\n[107,]   -6.383023        0.1024052     0.06143715     -0.005596399\n       diff(insee_tppre_c5_m3, 1) diff(bdf_tuc_c5_m2, 1)      noise\n[105,]                 0.03904254              0.3970705  0.5785851\n[106,]                 0.03904254              0.3970705  0.1141372\n[107,]                 0.03904254              0.3970705 -0.6226152\n\ntail(mod_ssm$smoothed_stdev, 3)\n\n       (Intercept) overhang_ipi1_c5 insee_bc_c5_m3 insee_oscd_c5_m2\n[105,]    3.213333       0.02268142     0.02921753       0.01501868\n[106,]    3.213333       0.02268142     0.02921753       0.01501868\n[107,]    3.213333       0.02268142     0.02921753       0.01501868\n       diff(insee_tppre_c5_m3, 1) diff(bdf_tuc_c5_m2, 1)     noise\n[105,]                 0.01202881             0.07757954 0.1554965\n[106,]                 0.01202881             0.07757954 0.1367629\n[107,]                 0.01202881             0.07757954 0.1460395\n\n\nLa composante filtering_states donne les estimations des coefficients en temps réel : la valeur à la date \\(t\\) correspond aux estimations des coefficients en utilisant les données jusqu’en \\(t-1\\). Ainsi, en estimant le modèle jusqu’en 2010T1, les coefficients obtenus sont ceux de la composante filtering_states de 2010T2 :\n\nsummary(dynlm(\n  formula = prod_c5 ~ overhang_ipi1_c5 + insee_bc_c5_m3 + insee_oscd_c5_m2\n  + diff(insee_tppre_c5_m3, 1) + diff(bdf_tuc_c5_m2, 1),\n  data = window(data, end = 2010)\n))\n\n\nTime series regression with \"ts\" data:\nStart = 1993(2), End = 2010(1)\n\nCall:\ndynlm(formula = prod_c5 ~ overhang_ipi1_c5 + insee_bc_c5_m3 + \n    insee_oscd_c5_m2 + diff(insee_tppre_c5_m3, 1) + diff(bdf_tuc_c5_m2, \n    1), data = window(data, end = 2010))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.93741 -0.36837 -0.02174  0.41270  1.50865 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                 0.687568   4.010977   0.171 0.864451    \noverhang_ipi1_c5            0.096558   0.029839   3.236 0.001947 ** \ninsee_bc_c5_m3             -0.003804   0.036838  -0.103 0.918081    \ninsee_oscd_c5_m2            0.027262   0.018837   1.447 0.152869    \ndiff(insee_tppre_c5_m3, 1)  0.047953   0.013331   3.597 0.000639 ***\ndiff(bdf_tuc_c5_m2, 1)      0.595962   0.104419   5.707 3.46e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6887 on 62 degrees of freedom\nMultiple R-squared:  0.8058,    Adjusted R-squared:  0.7902 \nF-statistic: 51.46 on 5 and 62 DF,  p-value: < 2.2e-16\n\nwindow(mod_ssm$filtering_states, start = 2010, end = c(2010,2))\n\n        (Intercept) overhang_ipi1_c5 insee_bc_c5_m3 insee_oscd_c5_m2\n2010 Q1   0.4262027       0.09515354   -0.001352874       0.02587391\n2010 Q2   0.6875678       0.09655775   -0.003804293       0.02726163\n        diff(insee_tppre_c5_m3, 1) diff(bdf_tuc_c5_m2, 1) noise\n2010 Q1                 0.04759521              0.5960833     0\n2010 Q2                 0.04795263              0.5959618     0\n\n\n\n\n\n\n\n\n\n\n\nExercice\n\n\n\nEstimer maintenant le modèle en utilisant les paramètres suivants :\n\nmodel_ssm <- ssm_lm(model_c5,\n       var_intercept = 0.01, fixed_var_intercept = FALSE,\n       var_variables = 0.01, fixed_var_variables = FALSE)\n\nLes paramètres fixed_var_intercept = FALSE et fixed_var_variables = FALSE permettent d’indiquer que les variances \\(q_1,\\dots, q_6\\) seront estimées. Les paramètres var_intercept et var_variables n’auront généralement aucun impact sur les résultats (puisque dans notre cas les variances sont estimées), ils interviennent toutefois dans le processus algorithmique : les modifier permet dans certains cas d’éviter des erreurs d’optimisation.\nRegarder les coefficients model_ssm$smoothed_states : quelles sont les variables qui varient dans le temps ? À partir de model_ssm$fitted, comparer la qualité prédictive de ce modèle avec les précédents.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLes variables fixes sont la constante et les carnets de commandes globaux :\n\nplot(model_ssm$smoothed_states[,-ncol(model_ssm$smoothed_states)])\n\n\n\n\nOn peut également vérifier en regardant les variances \\(\\sigma^2q_i\\) :\n\nmodel_ssm$parameters$parameters * model_ssm$parameters$scaling\n\n               (Intercept).var           overhang_ipi1_c5.var \n                  1.870276e-03                   3.863439e-04 \n            insee_bc_c5_m3.var           insee_oscd_c5_m2.var \n                  0.000000e+00                   1.097830e-06 \ndiff(insee_tppre_c5_m3, 1).var     diff(bdf_tuc_c5_m2, 1).var \n                  0.000000e+00                   3.462322e-03 \n                     noise.var \n                  3.548244e-01 \n\n\n\nres_ssm_is <- y - model_ssm$fitted[,\"smoothed\"]\nres_ssm_oos <- y - model_ssm$fitted[,\"filtering\"]\nrmse_ssm <- c(IS = rmse(res_ssm_is), OOS = rmse(res_ssm_oos))\nrbind(rmse_lm, rmse_rm, rmse_rm2, rmse_tvlm, rmse_ssm)\n\n                 IS       OOS\nrmse_lm   0.6990756 0.8494077\nrmse_rm   0.5731039 1.3826525\nrmse_rm2  0.6003532 0.8747103\nrmse_tvlm 0.5971192 0.9799976\nrmse_ssm  0.5422771 0.7441522\n\n# Après 2010\napply(window(ts.union(res_lm_oos, res_rm_oos, res_rm2_oos, res_tvlm_lastbw_oos, res_ssm_oos), start = 2010), 2, rmse)\n\n         res_lm_oos          res_rm_oos         res_rm2_oos res_tvlm_lastbw_oos \n          0.7863127           1.1067406           0.7050171           0.7231632 \n        res_ssm_oos \n          0.6863295 \n\n\nEn réalité, la composante filtering ne correspond pas exactement à de l’estimation en temps-réel car certains paramètres ne sont pas estimés de manière dynamique. Pour avoir une vraie estimation en temps-réel, il faudrait réestimer le modèle à chaque date : on peut pour cela utiliser la fonction ssm_lm_oos(). Pour que cette fonction marche, il faut parfois jouer sur les paramètres var_intercept et var_variables.\n\nmodel_ssm_oos <- ssm_lm_oos(model_c5,\n       var_intercept = 0.001, fixed_var_intercept = FALSE,\n       var_variables = 0.001, fixed_var_variables = FALSE)\nres_ssm_oos <- y - model_ssm_oos$prevision\n\nrmse_ssm <- c(IS = rmse(res_ssm_is), OOS = rmse(res_ssm_oos))\nrbind(rmse_lm, rmse_rm, rmse_rm2, rmse_tvlm, rmse_ssm)\n\n                 IS       OOS\nrmse_lm   0.6990756 0.8494077\nrmse_rm   0.5731039 1.3826525\nrmse_rm2  0.6003532 0.8747103\nrmse_tvlm 0.5971192 0.9799976\nrmse_ssm  0.5422771 0.7337112\n\napply(window(ts.union(res_lm_oos, res_rm_oos, res_rm2_oos, res_tvlm_lastbw_oos, res_ssm_oos), start = 2010), 2, rmse)\n\n         res_lm_oos          res_rm_oos         res_rm2_oos res_tvlm_lastbw_oos \n          0.7863127           1.1067406           0.7050171           0.7231632 \n        res_ssm_oos \n          0.6571734 \n\n\nOn peut enfin faire un graphique avec toutes les prévisions, en utilisant par exemple le package dygraphs :\n\nlibrary(dygraphs)\nprevs <- ts.intersect(y, y - res_lm_oos, y - res_rm2_oos, y - res_tvlm_lastbw_oos, y - res_ssm_oos)\ncolnames(prevs) <- c(\"y\", \"lm\", \"Reg par morceaux\", \"Reg locale\", \"SSM\")\ndygraph(prevs) %>% \n  dyRangeSelector(dateWindow = c(\"2010-01-01\", \"2019-12-01\")) %>%\n  dyOptions(colors = c(\"black\", \"red\", \"green\", \"blue\", \"purple\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercice facultatif\n\n\n\nL’objectif de cet exercice est d’estimer un nouveau modèle jusqu’en 2022T4 pour faire une prévision jusqu’en 2023T1 :\n\nCréer des indicatrices sur les 4 premiers trimestres de l’année 2020.\nEstimer un nouveau modèle dynlm en ajoutant ces indicatrices.\nEstimer un nouveau modèle espace-état.\nUtiliser les variables exogènes du modèle jusqu’en 2023T1 (on peut pour cela appliquer la fonction tvCoef::full_exogeneous_matrix() sur le modèle dynlm) et la dernière ligne de la composante \"smoothed_states\" pour effectuer des prévisions sur 2023T1.\n\n\n\n\n\n\n\n\n\nIndice (création des indicatrices)\n\n\n\n\n\nOn pourra utiliser le programme suivant pour créer les indicatrices :\n\nind <- cbind(time(manufacturing) == 2020, time(manufacturing) == 2020.25, time(manufacturing) == 2020.5,\ntime(manufacturing) == 2020.75)\nind <- ts(apply(ind,2, as.numeric), start = start(manufacturing), frequency = 4)\ncolnames(ind) <- sprintf(\"ind2020Q%i\", 1:4)\ndata <- ts.union(manufacturing, ind)\ncolnames(data) <- c(colnames(manufacturing), colnames(ind))\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nEstimation du modèle de régression linéaire :\n\nind <- cbind(time(manufacturing) == 2020, time(manufacturing) == 2020.25, time(manufacturing) == 2020.5,\ntime(manufacturing) == 2020.75)\nind <- ts(apply(ind,2, as.numeric), start = start(manufacturing), frequency = 4)\ncolnames(ind) <- sprintf(\"ind2020Q%i\", 1:4)\ndata <- ts.union(manufacturing, ind)\ncolnames(data) <- c(colnames(manufacturing), colnames(ind))\n\n\ndata <- ts.union(manufacturing, ind)\ncolnames(data) <- c(colnames(manufacturing), colnames(ind))\nmodel_c5_complet <- dynlm(\n  formula = prod_c5 ~ overhang_ipi1_c5 + insee_bc_c5_m3 + insee_oscd_c5_m2\n  + diff(insee_tppre_c5_m3, 1) + diff(bdf_tuc_c5_m2, 1) \n  + ind2020Q1 + ind2020Q2 + ind2020Q3 + ind2020Q4,\n  data = data\n)\nsummary(model_c5_complet)\n\n\nTime series regression with \"ts\" data:\nStart = 1990(2), End = 2022(4)\n\nCall:\ndynlm(formula = prod_c5 ~ overhang_ipi1_c5 + insee_bc_c5_m3 + \n    insee_oscd_c5_m2 + diff(insee_tppre_c5_m3, 1) + diff(bdf_tuc_c5_m2, \n    1) + ind2020Q1 + ind2020Q2 + ind2020Q3 + ind2020Q4, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.50121 -0.40188  0.00267  0.48994  1.57418 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                -6.924304   3.182453  -2.176   0.0315 *  \noverhang_ipi1_c5            0.115792   0.020951   5.527 1.91e-07 ***\ninsee_bc_c5_m3              0.065321   0.028967   2.255   0.0259 *  \ninsee_oscd_c5_m2           -0.009964   0.014757  -0.675   0.5008    \ndiff(insee_tppre_c5_m3, 1)  0.026459   0.011405   2.320   0.0220 *  \ndiff(bdf_tuc_c5_m2, 1)      0.361476   0.077713   4.651 8.49e-06 ***\nind2020Q1                  -5.195550   0.788939  -6.585 1.23e-09 ***\nind2020Q2                  -7.650566   1.654785  -4.623 9.53e-06 ***\nind2020Q3                  16.223534   1.482828  10.941  < 2e-16 ***\nind2020Q4                   3.324056   0.810984   4.099 7.55e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.7705 on 121 degrees of freedom\n  (131 observations effacées parce que manquantes)\nMultiple R-squared:  0.9393,    Adjusted R-squared:  0.9348 \nF-statistic: 208.1 on 9 and 121 DF,  p-value: < 2.2e-16\n\nprev_oos_lm_complet <- oos_prev(model_c5_complet)\n\nEstimation du modèle espace-état :\n\nmodel_ssm_complet <- ssm_lm(model_c5_complet,\n       var_intercept = 0.01, fixed_var_intercept = FALSE,\n       var_variables = 0.01, fixed_var_variables = FALSE)\n# # Rmq : on pourrait également fixer à 0 les variances des coefficients associées aux indicatrices :\n# model_ssm_complet <- ssm_lm(model_c5_complet,\n#         var_intercept = 0.01, fixed_var_intercept = FALSE,\n#         var_variables = c(rep(0.01,5), rep(0, 4)), \n#         fixed_var_variables = c(rep(FALSE,5), rep(TRUE, 4)))\n\nmodel_ssm_complet_oos <- ssm_lm_oos(model_c5_complet, date = 18*4,\n       var_intercept = 0.01, fixed_var_intercept = FALSE,\n       var_variables = 0.01, fixed_var_variables = FALSE)\n\nEnfin, pour calculer les prévisions\n\nX_variables = full_exogeneous_matrix(model_c5_complet)\nwindow(X_variables, start = 2022)\n\n        (Intercept) overhang_ipi1_c5 insee_bc_c5_m3 insee_oscd_c5_m2\n2022 Q1           1         7.629539          108.0              4.5\n2022 Q2           1         2.870669          105.8             -2.2\n2022 Q3           1         2.663170           97.9            -16.0\n2022 Q4           1         1.979440           96.2            -24.6\n2023 Q1           1         1.737138           98.7            -23.0\n        diff(insee_tppre_c5_m3, 1) diff(bdf_tuc_c5_m2, 1) ind2020Q1 ind2020Q2\n2022 Q1                      -20.1                  -0.23         0         0\n2022 Q2                        0.1                   0.53         0         0\n2022 Q3                       -9.7                   0.57         0         0\n2022 Q4                       10.1                  -1.88         0         0\n2023 Q1                       -1.9                  -0.49         0         0\n        ind2020Q3 ind2020Q4\n2022 Q1         0         0\n2022 Q2         0         0\n2022 Q3         0         0\n2022 Q4         0         0\n2023 Q1         0         0\n\nprevs_lm <- rowSums(X_variables %*% diag(coef(model_c5_complet)))\nprevs_lm <- prevs_lm[length(prevs_lm)]\nprevs_ssm <- rowSums(X_variables %*% diag(model_ssm_complet$smoothed_states[nrow(model_ssm_complet$smoothed_states), - ncol(model_ssm_complet$smoothed_states)]))\nprevs_ssm <- prevs_ssm[length(prevs_ssm)]\nfull_prevs <- ts.union(prev_oos_lm_complet$prevision,\n                       model_ssm_complet_oos$prevision)\nfull_prevs <- ts(rbind(full_prevs,\n                       c(prevs_lm, prevs_ssm)),\n                 start = start(full_prevs),\n                 frequency = frequency(full_prevs))\ndata_forecasts <- ts.union(manufacturing[,\"prod_c5\"], full_prevs)\ndata_forecasts <- window(data_forecasts, start = 2010)\ncolnames(data_forecasts) <- c(\"y\", \"lm\", \"SSM\")\ndygraph(data_forecasts) %>% \n  dyRangeSelector(dateWindow = c(\"2018-01-01\", \"2023-03-01\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotes de bas de page\n\n\n L’avantage de dynlm par rapport à lm est qu’il permet de gérer directement la différenciation des variables sans avoir à créer de variable temporaire.↩︎"
  }
]